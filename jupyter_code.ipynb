{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This script trains the model defined in model file on the seismic offset gathers\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import preprocessing\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from core.utils import *\n",
    "from core.data_loader import *\n",
    "from core.model import *\n",
    "from core.results import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(2019)\n",
    "np.random.seed(seed=2019)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Fix the random seeds\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_val_split(args):\n",
    "    # Load data\n",
    "    seismic_offsets = marmousi_seismic().squeeze()[:, 100:600]  # dim= No_of_gathers x trace_length\n",
    "    impedance = marmousi_model().T[:, 100:600]  # dim = No_of_traces x trace_length\n",
    "\n",
    "    # Split into train and val\n",
    "    train_indices = np.linspace(0, 2720, args.n_wells).astype(int)\n",
    "    val_indices = np.setdiff1d(np.arange(0, 2720).astype(int), train_indices)\n",
    "    x_train, y_train = seismic_offsets[train_indices], impedance[train_indices]\n",
    "    x_val, y_val = seismic_offsets[val_indices], impedance[val_indices]\n",
    "\n",
    "    # Standardize features and targets\n",
    "    x_train_norm, y_train_norm = (x_train - x_train.mean())/ x_train.std(), (y_train - y_train.mean()) / y_train.std()\n",
    "    x_val_norm, y_val_norm = (x_val - x_train.mean())/ x_train.std(), (y_val - y_train.mean()) / y_train.std()\n",
    "    seismic_offsets = (seismic_offsets - x_train.mean()) / x_train.std()\n",
    "\n",
    "    return x_train_norm, y_train_norm, x_val_norm, y_val_norm, seismic_offsets\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Define function to perform train-val split\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    \"\"\"\n",
    "    Sets up the model to train\n",
    "    \"\"\"\n",
    "    # Create a writer object to log events during training\n",
    "    writer = SummaryWriter(pjoin('runs', 'fifth_exp'))\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load splits\n",
    "    x_train, y_train, x_val, y_val, seismic = train_val_split(args)\n",
    "\n",
    "    # Convert to torch tensors in the form (N, C, L)\n",
    "    x_train = torch.from_numpy(np.expand_dims(x_train, 1)).float().to(device)\n",
    "    y_train = torch.from_numpy(np.expand_dims(y_train, 1)).float().to(device)\n",
    "    x_val = torch.from_numpy(np.expand_dims(x_val, 1)).float().to(device)\n",
    "    y_val = torch.from_numpy(np.expand_dims(y_val, 1)).float().to(device)\n",
    "    seismic = torch.from_numpy(np.expand_dims(seismic, 1)).float().to(device)\n",
    "\n",
    "    # Set up the dataloader for training dataset\n",
    "    dataset = SeismicLoader(x_train, y_train)\n",
    "    train_loader = DataLoader(dataset=dataset,\n",
    "                              batch_size=args.batch_size,\n",
    "                              shuffle=False)\n",
    "\n",
    "    # import tcn\n",
    "    model = TCN(1,\n",
    "                1,\n",
    "                args.tcn_layer_channels,\n",
    "                args.kernel_size,\n",
    "                args.dropout).to(device)\n",
    "\n",
    "    # Set up loss\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    # Define Optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 weight_decay=0.0001,\n",
    "                                 lr=0.001)\n",
    "\n",
    "    # Set up list to store the losses\n",
    "    train_loss = [np.inf]\n",
    "    val_loss = [np.inf]\n",
    "    iter = 0\n",
    "    # Start training\n",
    "    for epoch in range(args.n_epoch):\n",
    "        for x, y in train_loader:\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "            writer.add_scalar(tag='Training Loss', scalar_value=loss.item(), global_step=iter)\n",
    "            if epoch % 20 == 0:\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    y_pred = model(x_val)\n",
    "                    loss = criterion(y_pred, y_val)\n",
    "                    val_loss.append(loss.item())\n",
    "                    writer.add_scalar(tag='Validation Loss', scalar_value=loss.item(), global_step=iter)\n",
    "            print('epoch:{} - Training loss: {:0.4f} | Validation loss: {:0.4f}'.format(epoch,\n",
    "                                                                                        train_loss[-1],\n",
    "                                                                                        val_loss[-1]))\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    AI_inv = model(seismic)\n",
    "                fig, ax = plt.subplots()\n",
    "                ax.imshow(AI_inv[:, 0].detach().cpu().numpy().squeeze().T, cmap=\"rainbow\")\n",
    "                ax.set_aspect(4)\n",
    "                writer.add_figure('Inverted Acoustic Impedance', fig, iter)\n",
    "        iter += 1\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    # Set up directory to save results\n",
    "    results_directory = 'results'\n",
    "    seismic_offsets = np.expand_dims(marmousi_seismic().squeeze()[:, 100:600], 1)\n",
    "    seismic_offsets = torch.from_numpy((seismic_offsets - seismic_offsets.mean()) / seismic_offsets.std()).float()\n",
    "    with torch.no_grad():\n",
    "        model.cpu()\n",
    "        model.eval()\n",
    "        AI_inv = model(seismic_offsets)\n",
    "\n",
    "    if not os.path.exists(results_directory):\n",
    "        os.mkdir(results_directory)\n",
    "        print('Saving results...')\n",
    "    else:\n",
    "        print('Saving results...')\n",
    "\n",
    "    np.save(pjoin(results_directory, 'AI.npy'), marmousi_model().T[:, 100:600])\n",
    "    np.save(pjoin(results_directory, 'AI_inv.npy'), AI_inv.detach().numpy().squeeze())\n",
    "    print('Results successfully saved.')\n",
    "        #%%\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Hyperparams')\n",
    "    parser.add_argument('--n_epoch', nargs='?', type=int, default=1000,\n",
    "                        help='# of the epochs.')\n",
    "    parser.add_argument('--batch_size', nargs='?', type=int, default=19,\n",
    "                        help='Batch size. Default is mini-batch with batch size of 1.')\n",
    "    parser.add_argument('--tcn_layer_channels', nargs='+', type=int, default=[3, 5, 5, 5, 6, 6],\n",
    "                        help='No of channels in each temporal block of the tcn.')\n",
    "    parser.add_argument('--kernel_size', nargs='?', type=int, default=5,\n",
    "                        help='kernel size for the tcn')\n",
    "    parser.add_argument('--dropout', nargs='?', type=int, default=0.2,\n",
    "                        help='Dropout for the tcn')\n",
    "    parser.add_argument('--n_wells', nargs='?', type=int, default=19,\n",
    "                        help='# of well-logs used for training')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    train(args)\n",
    "    evaluate(args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Define train function\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}